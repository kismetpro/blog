---
title: 为什么人们说话像是语言模型：算法偏见如何通过“语言环路”重塑人类现实与自我认同
published: 2025-12-28
description: '为什么人们说话像是语言模型：算法偏见如何通过“语言环路”重塑人类现实与自我认同'
image: ../../assets/images/38526.jpg
tags: [科技频道]
category: '科技频道'
draft: false
lang: ''
---

## 为什么人们说话像是语言模型：算法偏见如何通过“语言环路”重塑人类现实与自我认同

Adam Aleksic 指出，社交媒体算法与 AI 大模型并非客观反映现实，而是通过利益驱动的筛选机制重塑人类语言与价值观。研究显示，ChatGPT 等模型因训练数据偏差频繁使用 "delve" 等词汇，反向导致人类在日常表达中模仿这种“AI 腔调”，形成正反馈循环。类似机制同样体现在文化消费中，Spotify 等平台将无意义的数据聚类赋予“hyperpop” 等标签，迫使创作者与用户迎合算法分类，使原本流动的兴趣被固化为刻板的身份认同。
编辑注：这种从“统计学聚类”到“本体论分类”的跃迁，本质上是算法权力的体现。平台通过将模糊的行为数据转化为刚性的社会标签，不仅制造了虚假的文化潮流，更在潜移默化中规训用户的政治倾向与自我认知。若缺乏对“算法循环效应”的批判性反思，公众将逐渐陷入由数据偏见构建的“幸存者偏差”世界，失去对真实多元现实的感知能力。

*TED*
